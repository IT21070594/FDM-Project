{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccdeb67",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc9cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad3fc6b",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with all columns\n",
    "dataset = pd.read_csv(\"Dataset/credit_card.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587dd485",
   "metadata": {},
   "source": [
    "# Data Exploration and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae62bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data types of the columns\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52506bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To explore a particular column\n",
    "dataset['merchant'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To explore a particular column\n",
    "dataset['category'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To explore a particular column\n",
    "dataset['city'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To explore a particular column\n",
    "dataset['state'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To explore a particular column\n",
    "dataset['job'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns the unique values in the column as an array.\n",
    "pd.unique(dataset['category'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6079bc",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb5946",
   "metadata": {},
   "source": [
    "### (1) Removing irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns we want to keep\n",
    "desired_columns = ['trans_date_trans_time', 'merchant', 'category', 'amt', 'state', 'city', 'city_pop', 'job', 'dob', 'is_fraud']\n",
    "\n",
    "# Filter the DataFrame to keep only the desired columns\n",
    "filtered = dataset[desired_columns]\n",
    "\n",
    "# 'filtered' now contains only the specified columns, and the rest are removed\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered = dataset.drop(['lat', 'long', 'trans_num', 'merch_long', 'merch_lat'], axis=1)\n",
    "# filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef4510",
   "metadata": {},
   "source": [
    "### (2) Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the “info()” function to have an idea about null columns.\n",
    "filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the null values count in the filtered dataset.\n",
    "filtered.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408a046",
   "metadata": {},
   "source": [
    "### (3) Handling duplicate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697851ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = filtered[filtered.duplicated()]\n",
    "\n",
    "# Print the duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle duplicates\n",
    "filtered.drop_duplicates(inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce48bc",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46137de6",
   "metadata": {},
   "source": [
    "### (1) Extracting date and time from 'trans_date_trans_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'trans_date_trans_time_column' to a datetime data type\n",
    "filtered = filtered.copy()\n",
    "filtered['trans_date_trans_time'] = pd.to_datetime(filtered['trans_date_trans_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f65da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datetime column into separate date and time columns\n",
    "filtered['trans_date'] = filtered['trans_date_trans_time'].dt.date\n",
    "filtered['trans_time'] = filtered['trans_date_trans_time'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the resulting DataFrame\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd3e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns we want to keep\n",
    "desired_columns = ['trans_date', 'trans_time', 'amt', 'merchant', 'category', 'job', 'dob', 'state', 'city', 'city_pop', 'is_fraud']\n",
    "\n",
    "# Filter the DataFrame to keep only the desired columns\n",
    "filtered = filtered[desired_columns]\n",
    "\n",
    "# 'filtered_df' now contains only the specified columns, and the rest are removed\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e130c",
   "metadata": {},
   "source": [
    "### (2)  Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c87d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables (using one-hot encoding)\n",
    "data = pd.get_dummies(filtered, columns=['city', 'state', 'job', 'merchant', 'category'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96092f5",
   "metadata": {},
   "source": [
    "# Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d2984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with the mapping of old column names to new column names\n",
    "column_mapping = {'amt': 'amount', 'city_pop': 'city_population'}\n",
    "\n",
    "# Use the 'rename()' method to rename the columns\n",
    "data.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# 'filtered' now has the columns with the new names\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to a csv\n",
    "data.to_csv(\"cleaned_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e069a",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance (using oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "X = data.drop(columns=['is_fraud'])\n",
    "y = data['is_fraud']\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
